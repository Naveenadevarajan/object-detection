{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfile = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "frozen_model = \"frozen_inference_graph.pb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn_DetectionModel(frozen_model, configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Labels: ['Human', 'Bicycle', 'Car', 'Motorbike', 'Aeroplane', 'Bus', 'Train', 'Truck', 'Boat', 'Traffic light', 'Fire hydrant', 'Stop sign', 'Parking meter', 'Bench', 'Bird', 'Cat', 'Dog', 'Horse', 'Sheep', 'Cow', 'Elephant', 'Bear', 'Zebra', 'Giraffe', 'Backpack', 'Umbrella', 'Handbag', 'Tie', 'Suitcase', 'Frisbee', 'Skis', 'Snowboard', 'Sports ball', 'Kite', 'Baseball bat', 'Baseball glove', 'Skateboard', 'Surfboard', 'Tennis racket', 'Bottle', 'Wine glass', 'Cup', 'Fork', 'Knife', 'Spoon', 'Bowl', 'Banana', 'Apple', 'Sandwich', 'Orange', 'Broccoli', 'Carrot', 'Hot dog', 'Pizza', 'Donut', 'Cake', 'Chair', 'Sofa', 'Pottedplant', 'Bed', 'Diningtable', 'Tvmonitor', 'Laptop', 'Mouse', 'Remote', 'Keyboard', 'Cell phone', 'Microwave', 'Oven', 'Toaster', 'Sink', 'Refrigerator', 'Book', 'Clock', 'Vase', 'Scissors', 'Teddy bear', 'Hair drier', 'Toothbrush']\n"
     ]
    }
   ],
   "source": [
    "Class_labels = []  # 80 Classes of Classification available in the COCO Dataset Collection\n",
    "with open(\"label.txt\", 'rt') as fpt:\n",
    "    Class_labels = fpt.read().strip(\"\\n\").split(\"\\n\")  # Extracting the .txt file into List of Labels\n",
    "\n",
    "print(\"List of Labels: \" + str(Class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO OF LABELS: 79\n"
     ]
    }
   ],
   "source": [
    "print(\"NO OF LABELS: \" + str(len(Class_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 000001C15E334B30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setInputSize(320, 320)\n",
    "model.setInputScale(1.0 / 127.5)\n",
    "model.setInputMean((127.5, 127.5, 127.5))\n",
    "model.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ca719bb8c107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mClassIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfidence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfThreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.55\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Class Index values start from 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# if Objects Found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mClassInd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBoxes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfidence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"samplevideo.mp4\")\n",
    "# Font options used in labelling the Objects in Frame\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        ClassIndex, Confidence, bbox = model.detect(frame, confThreshold=0.55)  # Class Index values start from 1 \n",
    "        if len(ClassIndex) != 0:  # if Objects Found\n",
    "            for ClassInd, Confid, Boxes in zip(ClassIndex.flatten(), Confidence.flatten(), bbox):\n",
    "                if ClassInd >=1 and ClassInd <=80:\n",
    "                    cv2.rectangle(frame, Boxes, (255, 0, 0), 2)  # Boxes overlayed around the Detected object\n",
    "                    string = str(Class_labels[ClassInd-1])  # the Label Displayed in the Image\n",
    "                    cv2.putText(frame, string, (Boxes[0]+10, Boxes[1]+40), font, fontScale=font_scale, color=(0, 255, 0), thickness=3)\n",
    "        cv2.imshow(\"OBJECT DETECTION\", frame)\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Font options used in labelling the Objects in Frame\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        ClassIndex, Confidence, bbox = model.detect(frame, confThreshold=0.55)  # Class Index values start from 1 \n",
    "        if len(ClassIndex) != 0:  # if Objects Found\n",
    "            for ClassInd, Confid, Boxes in zip(ClassIndex.flatten(), Confidence.flatten(), bbox):\n",
    "                if ClassInd >=1 and ClassInd <=80:\n",
    "                    cv2.rectangle(frame, Boxes, (255, 0, 0), 2)  # Boxes overlayed around the Detected object\n",
    "                    string = str(Class_labels[ClassInd-1])  # the Label Displayed in the Image\n",
    "                    cv2.putText(frame, string, (Boxes[0]+10, Boxes[1]+40), font, fontScale=font_scale, color=(0, 255, 0), thickness=3)\n",
    "        cv2.imshow(\"OBJECT DETECTION\", frame)\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
